---
title: SAM-CFFNet：基于 SAM 的滑坡智能识别跨特征融合网络

author: 
  - "Junchuan Yu"
date: "2024-7-16"
categories:
  - Posts
  - Deep learning
  - Article
image: https://pic1.zhimg.com/100/v2-0c695da78b2119b960785047eaf78bc8_r.jpg
toc: true
---

# SAM-CFFNet：基于 SAM 的滑坡智能识别跨特征融合网络


第一作者：郗来典，中国地质大学（北京），2101210160@email.cugb.edu.cn

通讯作者：于峻川，中国自然资源航空物探遥感中心，yujunchuan@mail.cgs.gov.cn


## 1 研究背景与意义

><p align="left"> 2023年初提出的Segment anything model（SAM）在零样本语义分割中表现出了强大的泛化能力。但在遥感语义分割场景下SAM的应用效果并不理想，一方面高度依赖用户提供的提示，另一方面在目标与背景区分度不高的情况下很难进行有效区分。为了充分利用SAM强大的特征提取能力，解决滑坡识别这类场景复杂且高度依赖先验知识的遥感解译识别问题，本文提出一种基于SAM的跨特征融合网络（SAM-CFFNet）。该模型利用SAM的Image Encoder提取多级特征，并利用我们提出的跨特征融合解码器（CFFD）生成高精度的分割结果。</p>


  
## 2 SAM-CFFNet介绍
### 2.1 SAM-CFFNet整体结构
  ![](https://pic1.zhimg.com/100/v2-0c695da78b2119b960785047eaf78bc8_r.jpg)
<p align="left"> 本文提出的 SAM-CFFNet 结构如上图所示，主要由两个部分组成：编码器 Image Encoder，解码器 CFFD。</p>


### 2.2 编码器
  ![](https://pic1.zhimg.com/100/v2-91f4e76bf51c4c583396787a2f2d9090_r.jpg)
<p align="left"> 本文使用SAM的Image Encoder作为编码器，结构如上图所示，用于获取图像的特征信息，输出四个不同层次的特征。</p>
  
### 2.3 解码器
<p align="left"> 解码器CFFD使用CFFM模块整合不同层次的特征，通过SFE模块提取浅层信息，并将这两种特征相融合，从而获得高精度的分割掩码。</p>
  
  ![](https://pic3.zhimg.com/100/v2-352233f7ef04107b6857bc2ccaff52d2_r.jpg)
<p align="left"> CFFM 由四个特征调整模块 （FAM） 和三个特征交叉融合结构 （FCFS） 组成。四个 FAM 分别负责对四个输入特征进行微调和调整大小。FCFS 负责四个特征的交叉融合。在每个 FCFS 模块中，四个输入特征进行交叉融合。 </p>
 
![](https://pic1.zhimg.com/100/v2-8e3b1350f1ffcff264f1abc6dc38dd5c_r.jpg)
<p align="left"> FAM 由两个MLP和一个Neck组成，这种设计减少了参数量,可以有效微调特征。此外使用残差结构可以减少信息丢失。</p>

## 3 主要实验结果
<p align="left"> 实验采用三个开源滑坡数据集作为实验数据集，具体信息如下：</p>


* 毕节滑坡数据集 
* Landslide4Sense 数据集
* GVLM 数据集: 

### 3.1 对比实验
<p align="left"> 在三个数据集上对比了SAM-CFFNet与Attention U-Net、DeepLabv3+、HRNet和SegFormer模型，证明了SAM-CFFNet有着更好的性能，IoU分别达到了77.13%、55.26%和73.87%</p>

![](https://pic2.zhimg.com/100/v2-afb5f56e55327b5f48c0f7f0425325f5_r.jpg)
<p align="left"> 上图为模型在毕节滑坡数据集上的分割效果，图中a,b,c,d,e分别表示SAM-CFFNet、Attention U-Net、DeepLabv3+、HRNet和SegFormer。</p>

![](https://pic3.zhimg.com/100/v2-368e303a3e5e852d33c1753cdabda71a_r.jpg)
<p align="left"> 上图为模型在Landslide4Sense 数据集上的分割效果，图中a,b,c,d,e分别表示SAM-CFFNet、Attention U-Net、DeepLabv3+、HRNet和SegFormer。</p>

![](https://pic3.zhimg.com/100/v2-e279a058d21d3f08a254f4382fbf4dde_r.jpg)
<p align="left"> 上图为模型在GVLM数据集上的分割效果，图中a,b,c,d,e分别表示SAM-CFFNet、Attention U-Net、DeepLabv3+、HRNet和SegFormer。</p>

### 3.2 解码器对比

<p align="left"> 为了展示CFFD的有效性，将其与Mask Decoder、PSP Decoder、ASPP Decoder和LawinASPP等解码器进行了对比，分别表示为 Model I、Model II、Model III 和 Model IV。</p>

![](https://pic3.zhimg.com/100/v2-866c0d95c85e85255032677c493cd1aa_r.jpg)
<p align="left"> 上图为模型在三个数据集上的分割效果，图中a,b,c,d,e分别表示SAM-CFFNet、Model I、Model II、Model III 和 Model IV。</p>

### 3.3 效率对比

![](https://pic4.zhimg.com/100/v2-00691da4b10d7067744556bb9916b08b_r.jpg)
<p align="left">SAM-CFFNet和Model I-IV的参数总数大于297 MB，FLOP大于1220 G，远大于其他模型。在可训练参数方面，SAM-CFFNet相对较少（4.06 MB），且精度最优。</p>

![](https://pic4.zhimg.com/100/v2-5766967818554de09cf9b18003eac8cf_r.jpg)
<p align="left">上图记录了这些模型的训练损失曲线，可以看到SAM-CFFNet在三个数据集上能够在10个Epoch内完成拟合，显著优于其他模型。</p>

## 4 结论
<p align="left"> 本研究提出的SAM-CFFNet作为SAM的一种新颖有效的应用，目的是提高SAM在滑坡识别应用中的精度，解决其在下游任务中性能下降和提示信息依赖等问题。 </p>
<p align="left"> 实验结果证明了SAM-CFFNet在滑坡识别任务中的有效性，展现了SAM模型在滑坡探测与监测领域中的巨大潜力，有助于推动SAM模型在地质灾害监测领域的进一步发展。</p>


**引用本文：**

Xi, L.; Yu, J.; Ge, D.; Pang, Y.; Zhou, P.; Hou, C.; Li, Y.; Chen, Y.; Dong, Y. SAM-CFFNet: SAM-Based Cross-Feature Fusion Network for Intelligent Identification of Landslides. Remote Sens. 2024, 16, 2334.https://doi.org/10.3390/rs16132334

Xi, L.; Yu, J.; Ge, D.; Pang, Y.; Zhou, P.; Hou, C.; Li, Y.; Chen, Y.; Dong, Y. SAM-CFFNet: SAM-Based Cross-Feature Fusion Network for Intelligent Identification of Landslides. Remote Sens. 2024, 16, 2334.https://doi.org/10.3390/rs16132334

  
  原文链接：[https://www.mdpi.com/2072-4292/16/13/2334/xml](https://www.mdpi.com/2072-4292/16/13/2334/xml)

  代码链接: [https://github.com/JunchuanYu/SAM-CFFNet](https://github.com/JunchuanYu/SAM-CFFNet)



---------------------------
请关注微信公众号【45度科研人】获取更多精彩内容，欢迎后台留言！

<span style="display: block; text-align: center; margin-left: auto; margin-right: auto;">
    <img src="https://dunazo.oss-cn-beijing.aliyuncs.com/blog/wechat-simple.png" width="300"  alt="">
</span>

--------------------------------------
为了促进沟通与交流，我们建立了「养生科研」学术交流群。这个平台不仅能够让大家迅速获取本公众号的资源，还为各位提供了一个共同探讨问题、交流思想的空间。有意向加入交流群的朋友们，可以通过添加小编的微信来获得入群邀请。请注意，在添加时请按照“加群-单位-研究方向-姓名”的格式备注您的信息，否则您的申请可能无法通过。


<span style="display: block; text-align: center; margin-left: auto; margin-right: auto;">
    <img src="https://dunazo.oss-cn-beijing.aliyuncs.com/blog/laidian.jpg" width="250"  alt="">
</span>

